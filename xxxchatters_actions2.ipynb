{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:04:08] Random_Chaos wondering who the violator and who the violatee\n",
      "\n",
      "[23:04:41] FunkyBoogieKing pounce-whomples erotic_kitty\n",
      "\n",
      "[23:06:26] T-Rex rolls in and strikes a pose\n",
      "\n",
      "[23:17:58] BigDickBBL is now known as BigDick.\n",
      "\n",
      "[23:30:49] Handyman shudders\n",
      "\n",
      "[23:33:08] Sanger{ek} softly pets my lil kitten and kisses between her ears\n",
      "\n",
      "[23:33:45] Fenderman1964 waves and sits down\n",
      "\n",
      "[23:35:54] Jothom looks around\n",
      "\n",
      "[23:37:30] Fenderman1964 waves and gets out of the way\n",
      "\n",
      "[23:40:55] Fenderman1964 is too old for that\n",
      "\n",
      "[23:46:08] Fenderman1964 minds his own business\n",
      "\n",
      "[23:51:49] Jothom lounges\n",
      "\n",
      "[23:55:58] erotic_kitty yawns and curls up on Sanger\n",
      "\n",
      "[23:56:21] Sanger snuggles my kitten\n",
      "\n",
      "[23:56:40] erotic_kitty purrssssssssssssssss\n",
      "\n",
      "[23:56:40] Fenderman1964 waves and sits out of the way\n",
      "\n",
      "[23:57:13] Sanger swats your bottom\n",
      "\n",
      "[23:57:43] Fenderman1964 shakes his head and quits\n",
      "\n",
      "[23:58:26] Sanger tucks my pet in all warm and cozy with her Smokey stuffy and reads her a bed time story from Asimovs Sci Fi\n",
      "\n",
      "[00:00:16] Fenderman1964 doesnt play and thus doesnt worry\n",
      "\n",
      "[00:02:07] DJ`liltech is now known as liltech.\n",
      "\n",
      "479403\n",
      "158959\n",
      "29066\n",
      "40\n",
      "55\n",
      "304\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import codecs\n",
    "from utils import in_blocklist\n",
    "\n",
    "blocklist = []\n",
    "blocklist.append('AWAYLEN=307 MAXTARGETS=20 WALLCHOPS WATCH=128 WATCHOPTS=A SILENCE=15 MODES=12 CHANTYPES=# PREFIX')\n",
    "blocklist.append('- * -')\n",
    "blocklist.append('XxXChatters.Com')\n",
    "blocklist.append('XxXChatters')\n",
    "blocklist.append('This server was created')\n",
    "blocklist.append('operator(s) online')\n",
    "blocklist.append('is now your displayed host')\n",
    "blocklist.append('Caps set:')\n",
    "blocklist.append('MAXCHANNELS')\n",
    "blocklist.append('http')\n",
    "blocklist.append('type it in the main room or a pm to the')\n",
    "blocklist.append('The topic is')\n",
    "blocklist.append('Topic set by')\n",
    "\n",
    "all_separated = []\n",
    "all_posts = []\n",
    "all_posts_410 = []\n",
    "all_posts_501 = []\n",
    "authors = {}\n",
    "authors_410 = {}\n",
    "authors_501 = {}\n",
    "\n",
    "def parse_all(files, separate):\n",
    "    for file in glob.glob(files):\n",
    "        lines = codecs.open(file, mode='r', encoding='utf-8')\n",
    "\n",
    "        for line in lines:\n",
    "            if not in_blocklist(blocklist, line.strip()): # blocked?\n",
    "                if line[0] is '[' and line.find(\"<\") is not -1:\n",
    "                    s = line\n",
    "                    sentence = s[s.find(\">\")+2:]\n",
    "                    time = s[s.find(\"[\")+1:s.find(\"]\")]\n",
    "                    author = s[s.find(\"<\")+1:s.find(\">\")]\n",
    "                    \n",
    "                    p = (time+' ' + author, sentence.strip().lower())\n",
    "                    all_posts.append(p)\n",
    "                    if separate in file:\n",
    "                        all_separated.append(p)\n",
    "\n",
    "                    if author not in authors: # save things\n",
    "                        authors[author] = set() # init list for author\n",
    "                    authors[author].add(sentence.strip().lower()) \n",
    "                else:\n",
    "                    if line.find('*') is not -1 and \") has joined #\" not in line and \") Quit (\" not in line and \") has left #\" not in line and \"6A\u000314thena\u000314, \u000f\u000306y\u000314o\u000314u \u000f\u000306n\u000314eve\u000314r\" not in line and \" sets mode: +\" not in line and \" is now known as \" not in line:\n",
    "                        time = line[line.find(\"[\")+1:line.find(\"]\")]\n",
    "                        author_beginning = line.find(\"* \")\n",
    "                        aa = line[author_beginning+2:]\n",
    "                        aa_end = author_beginning + 2 + aa.find(\" \")\n",
    "                        author = line[author_beginning+2:aa_end]\n",
    "                        sentence = line[aa_end + 1:]\n",
    "                        \n",
    "                        p = (time+' ' + author, sentence.strip().lower())\n",
    "                        all_posts.append(p)\n",
    "                        if separate in file:\n",
    "                            all_separated.append(p)\n",
    "\n",
    "                        if author not in authors: # save things\n",
    "                            authors[author] = set() # init list for author\n",
    "                        authors[author].add(sentence.strip().lower()) \n",
    "                    if \") has joined #\" in line or \") Quit (\" in line or \") has left #\" in line:\n",
    "                        time = line[line.find(\"[\")+1:line.find(\"]\")]\n",
    "                        author_beginning = line.find(\"* \")\n",
    "                        aa = line[author_beginning+2:]\n",
    "                        aa_end = author_beginning + 2 + aa.find(\" \")\n",
    "                        author = line[author_beginning+2:aa_end]\n",
    "                        if \") has joined #\" in line:\n",
    "                            author += \" JOINED THE ROOM\"\n",
    "                        else:\n",
    "                            author += \" LEFT THE ROOM\"\n",
    "                        sentence = \"\"\n",
    "                        p = (time+' ' + author, sentence)\n",
    "                        all_posts.append(p)\n",
    "                        if separate in file:\n",
    "                            all_separated.append(p)\n",
    "                            \n",
    "                        if author not in authors: # save things\n",
    "                            authors[author] = set() # init list for author\n",
    "                        authors[author].add(sentence) \n",
    "\n",
    "    for line in codecs.open('1006/410_utf8.txt', mode='r', encoding='utf-8'):\n",
    "        if ':' in line and not in_blocklist(blocklist, line.strip()): # blocked?:\n",
    "            sentence = line[line.find(\":\"):]\n",
    "            all_posts.append((author, sentence.strip().lower()))\n",
    "            all_posts_410.append((author, sentence.strip().lower()))\n",
    "\n",
    "            author = line[:line.find(\":\")]\n",
    "            if author not in authors: # save things\n",
    "                authors[author] = set() # init list for author\n",
    "            if author not in authors_410:\n",
    "                authors_410[author] = set()\n",
    "            authors[author].add(sentence.strip().lower())\n",
    "            authors_410[author].add(sentence.strip().lower())\n",
    "\n",
    "\n",
    "    for s in codecs.open(\"1006/501_utf8.txt\", mode='r', encoding='utf-8').readlines():\n",
    "        if ':' in s and '<' in s and 'has left the channel' not in s and 'has quit' not in s and 'joined the channel' not in s:\n",
    "            if not in_blocklist(blocklist, s.strip()): # blocked?\n",
    "                sentence = s[s.find(\">\")+2:]\n",
    "                author = s[s.find(\"<\")+1:s.find(\">\")]\n",
    "                if len(author) < 2:\n",
    "                    continue\n",
    "                \n",
    "                all_posts.append((author, sentence.strip().lower()))\n",
    "                all_posts_501.append((author, sentence.strip().lower()))\n",
    "                \n",
    "                if author not in authors: # save things\n",
    "                    authors[author] = set() # init list for author\n",
    "                if author not in authors_501:\n",
    "                    authors_501[author] = set()\n",
    "                authors[author].add(sentence.strip().lower())\n",
    "                authors_501[author].add(sentence.strip().lower()) \n",
    "        if ':' in s and '<' not in s and 'has left the channel' not in s and 'has quit' not in s and 'joined the channel' not in s and ' sets mode ' not in s:\n",
    "            print(s)\n",
    "            author_beginning = s.find('] ')\n",
    "            aa = s[author_beginning+2:]\n",
    "            aa_end = author_beginning + 2 + aa.find(\" \")\n",
    "            author = s[author_beginning+2:aa_end]\n",
    "            sentence = s[aa_end + 1:]\n",
    "            #print(author)\n",
    "            #print(sentence)\n",
    "            all_posts.append((author, sentence.strip().lower()))\n",
    "            all_posts_501.append((author, sentence.strip().lower()))\n",
    "\n",
    "            if author not in authors: # save things\n",
    "                authors[author] = set() # init list for author\n",
    "            if author not in authors_501:\n",
    "                authors_501[author] = set()\n",
    "            authors[author].add(sentence.strip().lower())\n",
    "            authors_501[author].add(sentence.strip().lower()) \n",
    "            #print(author)\n",
    "            #print(sentence)\n",
    "            \n",
    "            \n",
    "parse_all(\"xxxchatters_logs/*.log\", \"#chat\")\n",
    "#for file in glob.glob(\"xxxchatters_logs/*.log\"):\n",
    "print(len(all_posts))\n",
    "print(len(all_separated))\n",
    "print(len(authors))\n",
    "print(len(authors_410))\n",
    "print(len(authors_501))\n",
    "print(len(all_posts_410))\n",
    "print(len(all_posts_501))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onetoquiet': {'hello random_chaos sir', 'heya erotic_kitty'}, 'FunkyBoogieKing': {'see you guys tomorrow.', \"she's a-one spicy meat-ah-ball!!!\", 'pounce-whomples erotic_kitty', \"i didn't break you!!! \\xa0>>\", 'while the mischievous slave is away, the mischievous master will play.', \"alright, everyone, it's nighty-night winky time for funkyboogieking\"}, '@erotic_kitty': {'', 'hiyas jakkiline-cd winterwhisper and mr_magoo', 'well sanger might not like it if i m broken', 'hiyas maidtiffani and dirtyoldperv', 'hiyas subgirl4bbc', 'you whomped me lao', 'hiyas avgjoe40', 'wb keynotespkr', 'hiyas pantyhosehighheelsman', 'whats wrong handyman?', 'hiyas atticus48', 'hiyas iwhisper2clits', 'hiyas zelda', 'wb fenderman1964', '!djrocks', 'old?', 'hiyas ant35', 'hiyas cyrune', 'no worries fenderman1964', 'welcome back simian hugssssssssss', 'wb eedwardgrey', 'hiyas shynica', 'hiyas masterpiece', 'hiyas hentaibaka34m', 'hiyas sub_f', 'hiyas littledick-bigheart', 'that was his one of his first ring names', 'hiyas jj_black', 'wb stoneheart', 'hiyas chad26', 'hiyas curvybeauty', 'pendragon', 'wb viking', 'hiyas lori19 and james44', 'wb country_boy30', 'hiyas ruinme03', 'hiyas texguy', 'everytime i see your nick meanmark1 i wonder if you\\x92re an undertaker fan', 'hiyas schweetjohn', 'hiyas thegreatswitchbandit', 'mwah love', 'hiyas badguy', 'night all hugsssssssssssssssssss', 'hiyas swflguy', 'for what fenderman1964', 'hiyas sol', 'hiyas slutfucker', 'hiyas mike30', 'hiyas journey7', 'hiyas vixenvictoriax', 'hiyas chad masterdrew xdom', 'hiyas fenderman1964', 'hiyas hockeyguy', 'hiyas bigfeller', 'hiyas eedwardgrey', 'hiyas comeonman', 'hiyas s', 'hiyas blackstone', 'wb meanmark', 'hiyas maisy', 'hiyas jothom', 'hiyas treason', 'welcome violatef', 'wb olderjon and hiheeled_ticklishlady', 'hiyas sole_man'}, 'Violatef': {'oh random_chaos \\xa0why?', 'heya erotic_kitty \\xa0ty'}, 'jakkiline-cd': {'hi erotic_kitty'}, '+DJ`Mercury': {'radio meltdown: dj`liltech is playing \\xa0rm sponsor channel promo - #trivia_playpen', 'radio meltdown: dj`liltech is playing', 'radio meltdown: dj`liltech is playing \\xa0van halen - dance the night away', 'radio meltdown: dj`liltech is off --> coming up: radio meltdown: dj`mercury]', 'erotic_kitty thinks radio meltdown: dj`liltech rocks!!', 'radio meltdown: dj`liltech is playing \\xa0yellow claw - run away', 'sanger thinks radio meltdown: dj`liltech rocks!!', 'radio meltdown: dj`liltech is playing \\xa0zz top - la grange', 'radio meltdown: dj`liltech is playing \\xa0queen - a kind of magic', 'radio meltdown: dj`liltech is playing \\xa0syn city cowboys - run for my life', 'radio meltdown: dj`liltech is playing \\xa0men without hats - safety dance', 'radio meltdown: dj`liltech is playing \\xa0the police - every little thing she does is magic', 'radio meltdown: dj`mercury is playing \\xa0elton john - philadelphia freedom', 'radio meltdown: dj`liltech is playing \\xa0zz top - sharp dressed man', 'radio meltdown: dj`liltech is playing \\xa0electric light orchestra - strange magic', 'radio meltdown: dj`liltech is playing \\xa0iron maiden - run to the hills', 'radio meltdown: dj`liltech is playing \\xa0rm sponsor channel promo - #vamps`cafe', 'radio meltdown: dj`liltech is playing \\xa0walk the moon - shut up and dance', \"radio meltdown: dj`liltech is playing \\xa0zz top - i'm bad, i'm nationwide\", 'radio meltdown: dj`liltech is playing \\xa0dnce - cake by the ocean'}, 'Random_Chaos': {'wondering who the violator and who the violatee'}, 'WaywardGentleman': {'have a great night'}, '@erotic_kitty{S}': {'hiyas kinkyslavegirl', 'wb keynotespkr', 'geeze', 'hiyas t-rex', '!djrocks', 'my pleasure', 'wb winterwhisper', 'hiyas salsaguy', 'hiyas sweetliz', 'wb stolen tomato', 'heyyyyyyyyyyyyyyyyyyyyyyyy', 'hiyas nick3 hugsssssssssss', 'hiyas heavyballs', 'hiyas handyman', 'night lao', 'hiyas helen19 hiheeled_ticklishlady itjustslipped jayprez', 'hiyas alicia1forf', 'hiyas springrain', 'wb joycegg', 'hiyas oldhorn57', 'hiyas rockcockinpa', 'hiyas dante', 'hiyas lil-tigress hugssssssssssssssssssssssssssssssssssss', 'wb bd hugssssssssssss', 'hiyas jillvalentine', 'hiyas chaz', 'hiyas julia_for_f'}, 'JoyceGG': {'ty \\xa0kitty'}, 'T-Rex': {'hi hi erotic_kitty', '.ö/', 'rolls in and strikes a pose'}, 'Sanger': {'good night folks \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 play nice', 'awesome song', 'hey there lil tigress', 'snuggles my kitten', 'swats your bottom', 'no breaking my kitty', 'tucks my pet in all warm and cozy with her smokey stuffy and reads her a bed time story from asimovs sci fi', '!djrocks', 'say your goodnights', 'yw'}, '+shyNica': {'heya erotic_kitty'}, 'lil-tigress': {'heya erotic_kitty. huggggssssss.', 'heya sanger sir.'}, 'keynotespkr': {'hi erotic kitty', 'thnx e kitty'}, 'rst37': {'hi springrain', 'hello ladies', 'hi jillvalentine'}, 'Nick`3': {'huggggggs erotic_kitty'}, 'EEdwardGrey': {'hello erotic_kitty'}, '@DJ`liltech': {'good night erotic_kitty', 'ty sanger', 'later sanger', 'ty erotic_kitty'}, 'Hockeyguy': {'hi erotic_kitty'}, 'JayPrez': {'hello'}, 'BigDickBBL': {'slips back into the room', 'is now known as bigdick.'}, 'SpringRain': {'hi erotic_kitty'}, 'BigDick': {'hi springrain huggggggggssss', 'ty kitty hon hugggggggsssssss'}, 'Alicia1forF': {'hi erotic_kitty'}, 'Handyman': {'cool, as long as they don\\x92t respond...verbally....', \"pussy farts is one thing...talking clits...that's quite another....\", 'yikes', 'shudders', 'hi erotic_kitty'}, 'kinkyslavegirl': {'hi erotic_kitty'}, 'EEdwardGrey^': {'thank you erotic_kitty'}, 'iWhisper2Clits': {'erotic_kitty: \\xa0hello there'}, 'Littledick-bigheart': {'hiya erotic_kitty', 'hi goddessb'}, 'SwflGuy': {'hey there erotic_kitty'}, 'sweet_teresa': {'', 'are we going disneylandddddddddddddd', 'then yes', 'do they talk back', 'maybe he\\x92s dyslexic like me', 'i ask if they talk back', 'bad mike', 'clits', 'well he whispers to them', 'no slash'}, 'Pendragon': {'good night erotic_kitty', 'welcome recentlyrapedf', 'g night sanger'}, 'JJ_Black': {'hi erotic_kitty'}, 'Jothom': {'hi vixenvictoriax', 'lounges', 'hi sub_f', 'heya erotic_kitty', 'hello blonde86nc', 'hi curvybeauty', 'how are you doing vixenvictoriax?', 'looks around', 'hi everyone', 'hi goddessb'}, 'Sanger{ek}': {'softly pets my lil kitten and kisses between her ears'}, 'Fenderman1964': {'old wrestlers', 'waves and sits out of the way', 'doesn\\x92t play and thus doesn\\x92t worry', 'shakes his head and quits', 'minds his own business', 'don\\x92t mind me', 'is too old for that', 'waves and gets out of the way', 'waves and sits down'}, 'RuinMe03': {\"hey y'all\"}, 'FriendlyMonster': {'hiya blonde86nc', 'hiya curvybeauty', 'hi there feminist_teen'}, 'GoddessB': {'hello again all'}, 'Comeonman': {'heyas erotic_kitty'}, 'MeanMark1': {'ty kitty', '', 'gotcha', 'ahh no'}, 'BigFeller': {'hi erotic_kitty'}, 'vixenvictoriax': {'hi jothom', 'hi erotic_kitty'}, 'Country_Boy30': {'we just might', 'anyone up for fun'}, 'MikeinMiami': {'join /gangbang', '#join /gangbang'}, 'simian': {'typing one handed', 'switch the / and the #'}, 'dante': {'hi sweet_teresa'}, 'SchweetJohn': {'yo'}, 'Masterpiece': {'hello erotic_kitty'}, 'Curvybeauty': {'hi'}, 'erotic_kitty': {'yawns and curls up on sanger', 'purrssssssssssssssss'}, 'Soul-of-Darkness': {'subgirl4bbc'}, 'Pwner': {'wake up'}, 'DJ`liltech': {'is now known as liltech.'}}\n",
      "410: \n",
      "carrol: 53\n",
      "Louise: 28\n",
      "Valkyrie: 21\n",
      "Threeleggedcat: 20\n",
      "PlayfulBBC: 18\n",
      "@saffron{WH}: 17\n",
      "+DJ`Mercury: 16\n",
      "WhoGiveSaDamn: 15\n",
      "Silver_haired`Fox: 14\n",
      "Woman: 8\n",
      "Cruel`Intentions: 7\n",
      "guynextdoor: 7\n",
      "Anastatia: 7\n",
      "^fran: 7\n",
      "Jaems: 6\n",
      "+DJ`South: 6\n",
      "JFetish: 5\n",
      "gracie: 4\n",
      "Athena: 3\n",
      "saffron{WH}: 3\n",
      "TricksyM: 3\n",
      "jessica110: 2\n",
      "rst36: 2\n",
      "SensualDom: 2\n",
      "OldMaster: 2\n",
      "+WolvenHeart: 2\n",
      "Tyrant: 2\n",
      "[M]yEvilTwin: 1\n",
      "lonelyhousewife: 1\n",
      "collegegirlrp19: 1\n",
      "+ DJ`Mercury: 1\n",
      "+DJ1Mercury: 1\n",
      "Stacyshusband: 1\n",
      "MasterRenegade: 1\n",
      "+DJMercury`: 1\n",
      "dark-reign: 1\n",
      "maddogmoe: 1\n",
      "StacysHusband: 1\n",
      "Mutter: 1\n",
      "natron: 1\n",
      "\n",
      "501: \n",
      "@erotic_kitty: 65\n",
      "@erotic_kitty{S}: 27\n",
      "+DJ`Mercury: 20\n",
      "Sanger: 10\n",
      "sweet_teresa: 10\n",
      "Jothom: 10\n",
      "Fenderman1964: 9\n",
      "FunkyBoogieKing: 6\n",
      "Handyman: 5\n",
      "@DJ`liltech: 4\n",
      "MeanMark1: 4\n",
      "T-Rex: 3\n",
      "rst37: 3\n",
      "Pendragon: 3\n",
      "FriendlyMonster: 3\n",
      "onetoquiet: 2\n",
      "Violatef: 2\n",
      "lil-tigress: 2\n",
      "keynotespkr: 2\n",
      "BigDickBBL: 2\n",
      "BigDick: 2\n",
      "Littledick-bigheart: 2\n",
      "vixenvictoriax: 2\n",
      "Country_Boy30: 2\n",
      "MikeinMiami: 2\n",
      "simian: 2\n",
      "erotic_kitty: 2\n",
      "jakkiline-cd: 1\n",
      "Random_Chaos: 1\n",
      "WaywardGentleman: 1\n",
      "JoyceGG: 1\n",
      "+shyNica: 1\n",
      "Nick`3: 1\n",
      "EEdwardGrey: 1\n",
      "Hockeyguy: 1\n",
      "JayPrez: 1\n",
      "SpringRain: 1\n",
      "Alicia1forF: 1\n",
      "kinkyslavegirl: 1\n",
      "EEdwardGrey^: 1\n",
      "iWhisper2Clits: 1\n",
      "SwflGuy: 1\n",
      "JJ_Black: 1\n",
      "Sanger{ek}: 1\n",
      "RuinMe03: 1\n",
      "GoddessB: 1\n",
      "Comeonman: 1\n",
      "BigFeller: 1\n",
      "dante: 1\n",
      "SchweetJohn: 1\n",
      "Masterpiece: 1\n",
      "Curvybeauty: 1\n",
      "Soul-of-Darkness: 1\n",
      "Pwner: 1\n",
      "DJ`liltech: 1\n",
      "\n",
      "combined: \n",
      "@erotic_kitty: 65\n",
      "carrol: 53\n",
      "+DJ`Mercury: 36\n",
      "Louise: 28\n",
      "@erotic_kitty{S}: 27\n",
      "Valkyrie: 21\n",
      "Threeleggedcat: 20\n",
      "PlayfulBBC: 18\n",
      "@saffron{WH}: 17\n",
      "WhoGiveSaDamn: 15\n",
      "Silver_haired`Fox: 14\n",
      "Sanger: 10\n",
      "sweet_teresa: 10\n",
      "Jothom: 10\n",
      "Fenderman1964: 9\n",
      "Woman: 8\n",
      "Cruel`Intentions: 7\n",
      "guynextdoor: 7\n",
      "Anastatia: 7\n",
      "^fran: 7\n",
      "Jaems: 6\n",
      "+DJ`South: 6\n",
      "FunkyBoogieKing: 6\n",
      "JFetish: 5\n",
      "Handyman: 5\n",
      "gracie: 4\n",
      "@DJ`liltech: 4\n",
      "MeanMark1: 4\n",
      "Athena: 3\n",
      "saffron{WH}: 3\n",
      "TricksyM: 3\n",
      "T-Rex: 3\n",
      "rst37: 3\n",
      "Pendragon: 3\n",
      "FriendlyMonster: 3\n",
      "jessica110: 2\n",
      "rst36: 2\n",
      "SensualDom: 2\n",
      "OldMaster: 2\n",
      "+WolvenHeart: 2\n",
      "Tyrant: 2\n",
      "onetoquiet: 2\n",
      "Violatef: 2\n",
      "lil-tigress: 2\n",
      "keynotespkr: 2\n",
      "BigDickBBL: 2\n",
      "BigDick: 2\n",
      "Littledick-bigheart: 2\n",
      "vixenvictoriax: 2\n",
      "Country_Boy30: 2\n",
      "MikeinMiami: 2\n",
      "simian: 2\n",
      "erotic_kitty: 2\n",
      "[M]yEvilTwin: 1\n",
      "lonelyhousewife: 1\n",
      "collegegirlrp19: 1\n",
      "+ DJ`Mercury: 1\n",
      "+DJ1Mercury: 1\n",
      "Stacyshusband: 1\n",
      "MasterRenegade: 1\n",
      "+DJMercury`: 1\n",
      "dark-reign: 1\n",
      "maddogmoe: 1\n",
      "StacysHusband: 1\n",
      "Mutter: 1\n",
      "natron: 1\n",
      "jakkiline-cd: 1\n",
      "Random_Chaos: 1\n",
      "WaywardGentleman: 1\n",
      "JoyceGG: 1\n",
      "+shyNica: 1\n",
      "Nick`3: 1\n",
      "EEdwardGrey: 1\n",
      "Hockeyguy: 1\n",
      "JayPrez: 1\n",
      "SpringRain: 1\n",
      "Alicia1forF: 1\n",
      "kinkyslavegirl: 1\n",
      "EEdwardGrey^: 1\n",
      "iWhisper2Clits: 1\n",
      "SwflGuy: 1\n",
      "JJ_Black: 1\n",
      "Sanger{ek}: 1\n",
      "RuinMe03: 1\n",
      "GoddessB: 1\n",
      "Comeonman: 1\n",
      "BigFeller: 1\n",
      "dante: 1\n",
      "SchweetJohn: 1\n",
      "Masterpiece: 1\n",
      "Curvybeauty: 1\n",
      "Soul-of-Darkness: 1\n",
      "Pwner: 1\n",
      "DJ`liltech: 1\n"
     ]
    }
   ],
   "source": [
    "authors_410_second = []\n",
    "for a in authors_410:\n",
    "    authors_410_second.append((a, len(authors_410[a])))\n",
    "    \n",
    "authors_501_second = []\n",
    "for a in authors_501:\n",
    "    authors_501_second.append((a, len(authors_501[a])))\n",
    "    \n",
    "authors_410_second_sorted = sorted(authors_410_second, key=operator.itemgetter(1), reverse=True) \n",
    "authors_501_second_sorted = sorted(authors_501_second, key=operator.itemgetter(1), reverse=True) \n",
    "\n",
    "print(authors_501)\n",
    "\n",
    "authors_merged = {}\n",
    "for a in authors_410:\n",
    "    authors_merged[a] = len(authors_410[a])\n",
    "    \n",
    "#print(authors_merged)\n",
    "for a in authors_501:\n",
    "    if a in authors_merged:\n",
    "        authors_merged[a] += len(authors_501[a])\n",
    "    if a not in authors_merged:\n",
    "        authors_merged[a] = len(authors_501[a])\n",
    "        \n",
    "#print(authors_merged)\n",
    "\n",
    "authors_merged_second = []\n",
    "for a in authors_merged:\n",
    "    authors_merged_second.append((a, authors_merged[a]))\n",
    "    \n",
    "authors_merged_second_sorted = sorted(authors_merged_second, key=operator.itemgetter(1), reverse=True) \n",
    "\n",
    "print('410: ')\n",
    "for ps in authors_410_second_sorted:\n",
    "    print(ps[0] + ': ' + str(ps[1]))\n",
    "    \n",
    "print()\n",
    "print('501: ')\n",
    "for ps in authors_501_second_sorted:\n",
    "    print(ps[0] + ': ' + str(ps[1]))\n",
    "    \n",
    "\n",
    "print()\n",
    "print('combined: ')\n",
    "for ps in authors_merged_second_sorted:\n",
    "    print(ps[0] + ': ' + str(ps[1]))\n",
    "#authors_410.sort(key=takeSecond)\n",
    "#print(authors_410_sorted)\n",
    "#for a in authors_410:\n",
    "#    print(a + ': ' + str(len(authors_410[a])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in authors['carrol']:\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49231\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import string\n",
    "word_counts = dict()\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def preprocess_word(word):\n",
    "    word = word.replace('\\x02', '')\n",
    "    word = word.replace('\\x03', '')\n",
    "    word = word.replace('.', '')\n",
    "    word = ''.join([i for i in word if not i.isdigit()])\n",
    "\n",
    "    #word = word.translate(translator)\n",
    "    word = ''.join(e for e in word if e.isalnum())\n",
    "    return word\n",
    "\n",
    "\n",
    "for post in all_posts:\n",
    "    word_list = post[1].split()\n",
    "    for word in word_list:\n",
    "        word = preprocess_word(word)\n",
    "        #word = word.replace('\\x03', '')\n",
    "        #word = word.replace('.', '')\n",
    "\n",
    "        #word = word.translate(translator)\n",
    "        #word = ''.join(e for e in word if e.isalnum())\n",
    "        if len(word) < 1:\n",
    "            continue\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "\n",
    "sorted_word_counts = sorted(word_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def get_sorted_word_counts():\n",
    "    return sorted_word_counts\n",
    "\n",
    "v = get_sorted_word_counts()\n",
    "print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extra', 'arm', 'large', 'past', 'quickly', 'irc', 'human', 'rl', 'size', 'wine', 'leaves', 'firm', 'able', 'summer', 'dylan', 'devil', 'naderaax', 'kinky', 'jag']\n"
     ]
    }
   ],
   "source": [
    "def get_topn_percent(perc):\n",
    "    counts = get_sorted_word_counts()\n",
    "    l = len(counts)\n",
    "    max_index = int(perc*l)\n",
    "    top_n = []\n",
    "    #print(counts[:max_index])\n",
    "    for t in counts[:max_index]:\n",
    "        top_n.append(t[0])\n",
    "    return top_n\n",
    "\n",
    "def get_all_by_max_appearance(app):\n",
    "    counts = get_sorted_word_counts()\n",
    "    processed_counts = []\n",
    "    for c in counts:\n",
    "        if c[1] >= app:\n",
    "            processed_counts.append(c[0])\n",
    "        \n",
    "    return processed_counts\n",
    "\n",
    "def get_by_appearance_list(appearance):\n",
    "    # appearance = [2, 3, 4] # number indicating times of appearance\n",
    "    counts = get_sorted_word_counts()\n",
    "    processed_counts = []\n",
    "    for c in counts:\n",
    "        if c[1] in appearance:\n",
    "            processed_counts.append(c[0])\n",
    "        \n",
    "    return processed_counts\n",
    "    \n",
    "#topn = get_topn_percent(0.001)\n",
    "\n",
    "selected_appearances = get_by_appearance_list([110, 112])\n",
    "print(selected_appearances)\n",
    "\n",
    "#maxapp = get_all_by_max_appearance(2)\n",
    "#file = open(\"1106/chat_room_word_appearance.txt\", 'w')\n",
    "#for e in maxapp:\n",
    "#    try:\n",
    "#        file.write(e[0] + \", \" + str(e[1]) + '\\n')\n",
    "#    except:\n",
    "#        pass\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- to keep being evil ---- athena on the -------- with a new nerf bat\n",
      "jus to keep being -------- ---- athena on the backside with a new nerf bat\n"
     ]
    }
   ],
   "source": [
    "def remove_non_frequent(allowed_words, post, replace=True):\n",
    "    good_words = []\n",
    "    for word in post.lower().split():\n",
    "        pword = preprocess_word(word)\n",
    "        if pword in allowed_words:\n",
    "            good_words.append(pword)\n",
    "        else:\n",
    "            if replace:\n",
    "                replacement = \"\"\n",
    "                for char in word:\n",
    "                    replacement += \"-\"\n",
    "                good_words.append(replacement)\n",
    "    \n",
    "    return \" \".join(good_words)\n",
    "\n",
    "\n",
    "def remove_by_probability(allowed_words, always_allowed, post, chance, replace=True):\n",
    "    import random\n",
    "    good_words = []\n",
    "    for word in post.lower().split():\n",
    "        #pword = preprocess_word(word)\n",
    "        if word in always_allowed:\n",
    "            good_words.append(word)\n",
    "            continue\n",
    "            \n",
    "        if word in allowed_words:\n",
    "            good_words.append(word)\n",
    "        else:\n",
    "            if replace:\n",
    "                rv = random.uniform(0.0, 1.0)\n",
    "                if rv < chance:\n",
    "                    replacement = \"\"\n",
    "                    for char in word:\n",
    "                        replacement += \"-\"\n",
    "                    good_words.append(replacement)\n",
    "                else:\n",
    "                    good_words.append(word)\n",
    "    \n",
    "    return \" \".join(good_words)\n",
    "\n",
    "sentence_to_test = \"Jus to keep being evil<<<< wops Athena on the backside with a new nerf bat\"\n",
    "print(remove_non_frequent(get_topn_percent(0.1), sentence_to_test))\n",
    "\n",
    "print(remove_by_probability(get_topn_percent(0.1), get_topn_percent(0.01), sentence_to_test, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- ------- on the -------- with one of my new ---- ----\n",
      "bops saffron on the -------- with one of my new nerf bats\n"
     ]
    }
   ],
   "source": [
    "sentence_to_test = \"bops saffron on the backside with one of my new nerf bats\"\n",
    "print(remove_non_frequent(get_topn_percent(0.01), sentence_to_test))\n",
    "print(remove_non_frequent(get_topn_percent(0.1), sentence_to_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@erotic_kitty', 65), ('carrol', 53), ('+DJ`Mercury', 36), ('Louise', 28), ('@erotic_kitty{S}', 27), ('Valkyrie', 21), ('Threeleggedcat', 20), ('PlayfulBBC', 18), ('@saffron{WH}', 17), ('WhoGiveSaDamn', 15), ('Silver_haired`Fox', 14), ('Sanger', 10), ('sweet_teresa', 10), ('Jothom', 10), ('Fenderman1964', 9), ('Woman', 8), ('Cruel`Intentions', 7), ('guynextdoor', 7), ('Anastatia', 7), ('^fran', 7), ('Jaems', 6), ('+DJ`South', 6), ('FunkyBoogieKing', 6), ('JFetish', 5), ('Handyman', 5), ('gracie', 4), ('@DJ`liltech', 4), ('MeanMark1', 4), ('Athena', 3), ('saffron{WH}', 3)]\n",
      "['@erotic_kitty' 'carrol' '@erotic_kitty' '@erotic_kitty' '@erotic_kitty'\n",
      " 'carrol' '@erotic_kitty' '@erotic_kitty' 'carrol' 'carrol' 'carrol'\n",
      " 'carrol' '@erotic_kitty' '@erotic_kitty' 'carrol' '@erotic_kitty'\n",
      " '@erotic_kitty' 'carrol' '@erotic_kitty' '@erotic_kitty']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_by_probability(authors_list, count, topn = 30):\n",
    "    author_probability = {}\n",
    "    \n",
    "    for authors in authors_list:\n",
    "        for key, value in authors.items():\n",
    "            if key not in author_probability:\n",
    "                author_probability[key] = len(value)\n",
    "            else:\n",
    "                author_probability[key] += len(value)\n",
    "                \n",
    "    author_probability_counts = sorted(author_probability.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    #print(author_probability_counts[:topn])\n",
    "\n",
    "    sum_sentences = 0\n",
    "    for v in author_probability_counts[:topn]:\n",
    "        sum_sentences += v[1]\n",
    "\n",
    "    author_probability_final = {}\n",
    "    author_list = []\n",
    "    prob_list = []\n",
    "\n",
    "    for v in author_probability_counts[:topn]:\n",
    "        author_probability_final[v[0]] = v[1]/float(sum_sentences)\n",
    "        author_list.append(v[0])\n",
    "        prob_list.append(v[1]/float(sum_sentences))\n",
    "\n",
    "    final_autor_list = np.random.choice(\n",
    "      author_list, \n",
    "      count,\n",
    "      p=prob_list\n",
    "    )\n",
    "\n",
    "    return final_autor_list\n",
    "\n",
    "def get_topn_authors(author_lists, n):\n",
    "    author_probability = {}\n",
    "    \n",
    "    for author_list in author_lists:\n",
    "        for key, value in author_list.items():\n",
    "            if key not in author_probability:\n",
    "                author_probability[key] = len(value)\n",
    "            else:\n",
    "                author_probability[key] += len(value)\n",
    "\n",
    "    author_probability_counts = sorted(author_probability.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    return author_probability_counts[:n]\n",
    "\n",
    "#print(get_by_probability(authors, 20))\n",
    "#print(get_by_probability(authors_410, 20))\n",
    "#print(get_by_probability(authors_501, 20))\n",
    "\n",
    "print(get_topn_authors([authors_410,authors_501], 30))\n",
    "print(get_by_probability([authors_410,authors_501], 20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load osc config and parse for later use\n",
    "import csv\n",
    "\n",
    "def load_osc_config(file_name):\n",
    "    config = {}\n",
    "    with open(file_name, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter='\\t', quotechar='|')\n",
    "        index = 0\n",
    "        for row in reader:\n",
    "            if index > 0:\n",
    "                #print(row)\n",
    "                for i in range(len(row)):\n",
    "                    config[i].append(row[i])\n",
    "            else:\n",
    "                config[0] = []\n",
    "                config[1] = []\n",
    "                config[2] = []\n",
    "                config[3] = []\n",
    "                config[4] = []\n",
    "            index += 1\n",
    "    \n",
    "    return config\n",
    "            \n",
    "osc_config = load_osc_config('osc_config.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-47a6c1561ee5>:33: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(config) is not len(lists), \"len of config and lists needs to be the same\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "def generate_lines_linear(count):\n",
    "    return_lines = []\n",
    "    while len(return_lines) < count:\n",
    "#    for i in range(1, count):\n",
    "        sentence = random.choice(all_posts)[1]\n",
    "        perc = len(return_lines)/float(count)\n",
    "\n",
    "        topn = get_topn_percent(perc)\n",
    "        #print(perc)\n",
    "        #print(len(topn))\n",
    "        #print(sentence)\n",
    "        stripped_post = remove_non_frequent(topn, sentence.strip().lower())\n",
    "        if len(stripped_post) > 20 and stripped_post not in return_lines:\n",
    "            return_lines.append(stripped_post)\n",
    "        #print(str(perc) + \": \" + stripped_post)\n",
    "        \n",
    "    return return_lines\n",
    "        \n",
    "def generate_lines_from(fromp, step, count):\n",
    "    for i in range(count):\n",
    "        sentence = random.choice(all_posts)\n",
    "        perc = fromp + i * step\n",
    "\n",
    "        topn = get_topn_percent(perc)\n",
    "        #print(len(topn))\n",
    "        stripped_post = remove_non_frequent(topn, sentence[1].strip().lower())\n",
    "        print(\"{:.6f}\".format(perc) + \": \" + stripped_post)\n",
    "        \n",
    "def generate_by_osc(config, lists, offset=90):\n",
    "    assert(len(config) is not len(lists), \"len of config and lists needs to be the same\")\n",
    "\n",
    "    index = 0\n",
    "    possible_words = []\n",
    "    # length of generated sentences is determined by osc/curve data\n",
    "    length = len(config[0])\n",
    "    for l in lists:\n",
    "        _config = config[index]\n",
    "        _min = l[0]\n",
    "        _max = l[1]\n",
    "        app_list = []\n",
    "        for i in range(_min, _max+1):\n",
    "            app_list.append(i)\n",
    "        \n",
    "        # all allowed words\n",
    "        selected_appearances = get_by_appearance_list(app_list)\n",
    "        possible_words.append((selected_appearances, _config))\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    # all words with min appearance of 500 are always allowed\n",
    "    always_allowed = get_all_by_max_appearance(500)\n",
    "        \n",
    "    finished_sentences = []\n",
    "    for i in range(length):\n",
    "        #s = random.choice(all_posts)[1]\n",
    "        s = all_separated[offset+i][1]\n",
    "        a = all_separated[offset+i][0]\n",
    "        # don't process djs\n",
    "        if 'DJ`Mercury' in a or 'DJ`Protea' in a:\n",
    "            finished_sentences.append((a, s))\n",
    "            continue\n",
    "            \n",
    "        for p in possible_words:\n",
    "            _words = p[0]\n",
    "            probability = float(p[1][i])\n",
    "            s = remove_by_probability(_words, always_allowed, s, probability)\n",
    "        \n",
    "        finished_sentences.append((a, s))\n",
    "    \n",
    "    return finished_sentences\n",
    "\n",
    "def render_plain(out_filename, line_count, offset):\n",
    "    outfile = codecs.open(out_filename, mode='w', encoding='utf-8')\n",
    "    for i in range(line_count):\n",
    "        s = all_separated[offset+i][1]\n",
    "        a = all_separated[offset+i][0]\n",
    "        outfile.write(a + ': ' + s + '\\n')\n",
    "    outfile.close()\n",
    "\n",
    "def render_by_osc(osc_config, out_filename, offset):\n",
    "    lists = []\n",
    "    lists.append((1, 5))\n",
    "    lists.append((6, 20))\n",
    "    lists.append((21, 50))\n",
    "    #lists.append((51, 100))\n",
    "    #lists.append((101, 500))\n",
    "    osc_config = load_osc_config(osc_config)\n",
    "    generated = generate_by_osc(osc_config, lists, offset)\n",
    "\n",
    "    outfile = codecs.open(out_filename, mode='w', encoding='utf-8')\n",
    "    for line in generated:\n",
    "        outfile.write(line[0] + ': ' + line[1] + '\\n')\n",
    "    outfile.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@erotic_kitty' '@erotic_kitty' '@DJ`liltech']\n"
     ]
    }
   ],
   "source": [
    "auth = get_by_probability([authors_410,authors_501], 300)\n",
    "print(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% (126709 of 130000) |############## | Elapsed Time: 20:20:13 ETA:   0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# samples random lines from corpus, add a author from act1&2 by distribution and outout after a certain length of the line\n",
    "# randomly add entrences and exits from the last 10 of the top active 30 authors of act1&2\n",
    "# entire corpus processed and saved in one 7.5mb text file\n",
    "\n",
    "#random.seed(1)\n",
    "from progressbar import ProgressBar, Bar, Percentage\n",
    "\n",
    "max_count = 170000\n",
    "#auth = get_by_probability([authors_410,authors_501], max_count)\n",
    "\n",
    "def generate_lines_maxapp(count, maxapp):\n",
    "    return_lines = []\n",
    "    while len(return_lines) < count:\n",
    "#    for i in range(1, count):\n",
    "        #perc = len(return_lines)/float(count)\n",
    "        #perc = 0.5\n",
    "        sentence = random.choice(all_posts)[1]\n",
    "        if 'radio meltdown' in sentence:\n",
    "            continue\n",
    "        #topn = get_all_by_max_appearance(maxapp)\n",
    "        topn = get_topn_percent(maxapp)\n",
    "        stripped_post = remove_non_frequent(topn, sentence.strip().lower())\n",
    "        #if len(stripped_post) > 20 and len(stripped_post) < 50 and stripped_post not in return_lines:\n",
    "        if stripped_post not in return_lines:\n",
    "            return_lines.append(stripped_post)\n",
    "        #print(str(perc) + \": \" + stripped_post)\n",
    "        \n",
    "    return return_lines\n",
    "\n",
    "def process_all(maxapp):\n",
    "    return_lines = []\n",
    "    for p in all_posts:\n",
    "        sentence = p[1]\n",
    "        if 'radio meltdown' in sentence:\n",
    "            continue\n",
    "        topn = get_topn_percent(maxapp)\n",
    "        stripped_post = remove_non_frequent(topn, sentence.strip().lower())\n",
    "        if stripped_post not in return_lines:\n",
    "            return_lines.append(stripped_post)\n",
    "        \n",
    "    return return_lines\n",
    "\n",
    "outfile = codecs.open('1606_only_top0.025_all_authordistfix.txt', mode='w')\n",
    "\n",
    "# 20 top authors from 401 & 510\n",
    "auth_text = get_by_probability([authors_410,authors_501], max_count, 20)\n",
    "auth_io = get_topn_authors([authors_410,authors_501], 30)[-10:] # get_by_probability([authors_410,authors_501], 50, 30)[-10:]\n",
    "\n",
    "index = 0\n",
    "#lines = generate_lines_maxapp(max_count, 0.025)\n",
    "lines = process_all(0.025)\n",
    "print(len(lines))\n",
    "for line in lines:\n",
    "    l = ''.join(line)\n",
    "    outfile.write(auth_text[index] + ': ' + l + '\\n')\n",
    "    pbar.update(index)\n",
    "    if random.uniform(0, 1) > 0.7:\n",
    "        lj = \"\"\n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            lj = \" LEFT THE ROOM\"\n",
    "        else:\n",
    "            lj = \" JOINED THE ROOM\"\n",
    "        outfile.write(random.choice(auth_io)[0] + lj + '\\n')\n",
    "    \n",
    "    index += 1\n",
    "\n",
    "#pbar.update(max_count)\n",
    "outfile.close()\n",
    "print('finished')\n",
    "# random in/outs for last 10\n",
    "# top_n 2000 / 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no no no no\n",
      "annnnoooooooorrrrrraaaaaaaaaaaaa\n",
      "i know you knew, i just wanna know the interest of it, knowing that you know\n",
      "we have snow nordicgoddess but not enough to be snowed in .... yet lol\n",
      "no pwincess_aria no no no no\n",
      "pretends to know nothing then no one expects me to know anything\n",
      "no nononononono\n",
      "nnnnnoooo more poucing, hehe\n",
      "nnnnnooooooooooooooooooooooo\n",
      "yeah i know dj`annora not a good thing right now\n",
      "\u0002\u000307,01 limits: \u000300 no pee and scat, no permanent injuries, no animals nor kids\n",
      "lol no no no no\n",
      "nnnnnnnnnnnooooooooooooo\n"
     ]
    }
   ],
   "source": [
    "# attempt to find similar sentences by matching vocabulary\n",
    "# FAILED NOT USED\n",
    "\n",
    "#li = ['her', 'her', 'her', 'he']\n",
    "li = ['are', 'fake']\n",
    "li = ['what', 'she', 'does']\n",
    "#li = ['what', 'what', 'what']\n",
    "li = ['is', 'is', 'is', 'is']\n",
    "li = ['being'] * 3\n",
    "\n",
    "#li = ['good', 'good', 'am']\n",
    "#li = ['here', 'here', 'here']\n",
    "#li = ['nice', 'nice', 'very']\n",
    "#li = ['well', 'well']\n",
    "#li = ['ll', 'll', 'll', 'll']\n",
    "li = ['no'] * 4\n",
    "#li = ['just', 'well', 'i']\n",
    "index = 0\n",
    "for post in all_posts:\n",
    "    p = post[1]\n",
    "    #print(p)\n",
    "    success = True\n",
    "    for l in li:\n",
    "        if l in p:\n",
    "            index = p.find(l)\n",
    "            length = len(l)\n",
    "            endindex = index + length\n",
    "            subs = p[index:endindex] \n",
    "            leftover = p[:index] + p[endindex:]\n",
    "            p = leftover\n",
    "        else:\n",
    "            success = False\n",
    "    if success and len(post[1]) < 80: \n",
    "        print(post[1])\n",
    "    index += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: to be ---- to see\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (1281 of 164986) |                  | Elapsed Time: 0:00:15 ETA:   0:27:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched pattern 2: Athena: -------- i enjoy the open air ---------- such as ------ or ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% (3173 of 164986) |                  | Elapsed Time: 0:00:34 ETA:   0:26:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched pattern 1: Jothom: --- why im ------------ tired and body -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% (16781 of 164986) |#                | Elapsed Time: 0:02:55 ETA:   0:25:18"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched pattern 0: +DJ`Mercury: so by the ----- of ---- --- and she was --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% (45377 of 164986) |####             | Elapsed Time: 0:07:50 ETA:   0:21:19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched pattern 2: Silver_haired`Fox: damn i thought i was ---- thin at --- and ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (164985 of 164986) |############### | Elapsed Time: 0:29:25 ETA:   0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched pattern 2: Athena: -------- i enjoy the open air ---------- such as ------ or ---------\n",
      "matched pattern 1: Jothom: --- why im ------------ tired and body -----\n",
      "matched pattern 0: +DJ`Mercury: so by the ----- of ---- --- and she was --\n",
      "matched pattern 2: Silver_haired`Fox: damn i thought i was ---- thin at --- and ---\n"
     ]
    }
   ],
   "source": [
    "# todo: 1406\n",
    "# insert sentence into parser\n",
    "# extract gramatical structure\n",
    "# try to match through corpus\n",
    "# use pre-processed text, with dashes \n",
    "# FAILED NOT USED\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "from progressbar import ProgressBar, Bar, Percentage\n",
    "\n",
    "# punctation is NFP or PUNCT\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_tag_sequence(sen, detailed=False):\n",
    "    doc = nlp(sen)\n",
    "    sentence_pos_list = []\n",
    "    sentence_tag_list = []\n",
    "\n",
    "    for token in doc:\n",
    "        sentence_pos_list.append(token.pos_)\n",
    "        sentence_tag_list.append(token.tag_)\n",
    "    \n",
    "    if detailed:\n",
    "        return sentence_tag_list\n",
    "    \n",
    "    return sentence_pos_list\n",
    "\n",
    "def match_sequence(seq_to_match, seq_of_target):\n",
    "    to_match = ''.join(seq_to_match)\n",
    "    of_target = ''.join(seq_of_target)\n",
    "    if to_match in of_target:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def match_sequences(sequences, seq_of_target):\n",
    "    mmm = []\n",
    "    for s in sequences:\n",
    "        mmm.append(match_sequence(s, seq_of_target))\n",
    "    return mmm\n",
    "\n",
    "    \n",
    "input_file = open('1406_only_top0.025_all.txt', mode='r', encoding='utf8').readlines()\n",
    "\n",
    "detailed = True    \n",
    "\n",
    "ssss = []\n",
    "ssss.append('---- and i was ----')\n",
    "ssss.append('---- green and red ----')\n",
    "ssss.append('---- such as ---- or ----')\n",
    "ssss.append('---- hi ---- and ----')\n",
    "ssss.append('---- of the wall ---- of the bank')\n",
    "taglist = []\n",
    "for s in ssss:\n",
    "    taglist.append(get_tag_sequence(s, detailed))\n",
    "    \n",
    "print('input: ' + sentence)\n",
    "matched_sentences = []\n",
    "index = 0\n",
    "bar = ProgressBar(widget=[Percentage(), Bar()], maxval=len(input_file)).start()\n",
    "for line in input_file:\n",
    "    if len(line) > 2:\n",
    "        tseq = get_tag_sequence(line.rstrip(), detailed)\n",
    "        matched = match_sequences(taglist, tseq)\n",
    "        ii = 0\n",
    "        for m in matched:\n",
    "            if m:\n",
    "                matched_sentences.append('matched pattern ' + str(ii) + ': ' + line.rstrip())\n",
    "                print('matched pattern ' + str(ii) + ': ' + line.rstrip())\n",
    "            else:\n",
    "                pass\n",
    "            ii += 1\n",
    "        index += 1\n",
    "        #if index > 2000:\n",
    "        #    break\n",
    "        bar.update(index)\n",
    "for m in matched_sentences:\n",
    "    print(m)\n",
    "if len(matched_sentences) == 0:\n",
    "    print('no results :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses big corpus of dashed out text and matches by percent the occence of a special list of very common words\n",
    "# kinda FAILED not used\n",
    "\n",
    "import spacy\n",
    "import random\n",
    "from progressbar import ProgressBar, Bar, Percentage\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "possible = ['for', 'her', 'that', 'hello', 'on', 'me', 'hey', 'are', 'with', 'good', 'all', 'im', 'have', 'as', 'up', 'at', 'your', \n",
    "            'not', 'like', 'his', 'be', 'just', 'no', 'so', 'its', 'how', 'back', 'out', 'one', 'but', 'was', 'what', 'if', 'dont', \n",
    "            'well', 'here', 'or', 'she', 'we', 'do', 'nice', 'into']\n",
    "input_file = open('1406_only_top0.025_all.txt', mode='r', encoding='utf8').readlines()\n",
    "max_line_counter = 0\n",
    "out_file = open('1406_min5_words_relative0.45.txt', 'w')\n",
    "perc = 0.45\n",
    "\n",
    "\n",
    "for line in input_file:\n",
    "    counter = 0\n",
    "    wordcount = len(line.split())\n",
    "    \n",
    "    for word in line.split():\n",
    "        for p in possible:\n",
    "            if word == p:\n",
    "                counter += 1\n",
    "    if counter/float(wordcount) > perc and wordcount > 10:\n",
    "        out_file.write(line)\n",
    "        print(line)\n",
    "    max_line_counter += 1\n",
    "    #if max_line_counter > 90000:\n",
    "    #    break\n",
    "    \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure ONE\n",
    "\n",
    "import random\n",
    "from progressbar import ProgressBar, Bar, Percentage\n",
    "\n",
    "possible = ['for', 'her', 'that', 'hello', 'on', 'me', 'hey', 'are', 'with', 'good', 'all', 'im', 'have', 'as', 'up', 'at', 'your', \n",
    "            'not', 'like', 'his', 'be', 'just', 'no', 'so', 'its', 'how', 'back', 'out', 'one', 'but', 'was', 'what', 'if', 'dont', \n",
    "            'well', 'here', 'or', 'she', 'we', 'do', 'nice', 'into']\n",
    "\n",
    "#input_file = open('1406_only_top0.025_all.txt', mode='r', encoding='utf8').readlines()\n",
    "input_file = open('1606_only_top0.025_all_authordistfix.txt', mode='r', encoding='utf8').readlines()\n",
    "max_line_counter = 0\n",
    "out_file = open('1506_structure_01.txt', 'w')\n",
    "outfile.write('ACT 3 - STRUCTURE 1\\n')\n",
    "\n",
    "perc = 0.3\n",
    "chosen = []\n",
    "wordcount_min = 10\n",
    "\n",
    "for line in input_file:\n",
    "    #perc += 0.002\n",
    "    counter = 0\n",
    "    #print(line)\n",
    "    line = line.split(':')\n",
    "    \n",
    "    if len(line) < 2:\n",
    "        continue\n",
    "    auth = line[0]\n",
    "    line = line[1]\n",
    "    if len(line) < 3:\n",
    "        continue\n",
    "    wordcount = len(line.split())\n",
    "\n",
    "\n",
    "    for word in line.split():\n",
    "        for p in possible:\n",
    "            if word == p:\n",
    "                counter += 1\n",
    "\n",
    "    if counter / float(wordcount) > perc and wordcount > wordcount_min:\n",
    "        perc += 0.002\n",
    "        chosen.append(line)\n",
    "        out_file.write(auth + ': ' + line)\n",
    "        print(str(perc) + ': ' + line.rstrip())\n",
    "        \n",
    "    if len(chosen) > 150:\n",
    "        break\n",
    "\n",
    "print('###########################################################################################################################')\n",
    "print('second part')\n",
    "print('###########################################################################################################################')\n",
    "\n",
    "short_chosen = []\n",
    "min_len = 50\n",
    "max_len = 140\n",
    "for line in input_file:\n",
    "    line = line.split(':')\n",
    "    if len(line) < 2:\n",
    "        continue \n",
    "    auth = line[0]\n",
    "    line = line[1]\n",
    "    if len(line) < 3:\n",
    "        continue\n",
    "    counter = 0\n",
    "    wordcount = len(line.split())\n",
    "    linelen = len(line)\n",
    "    \n",
    "    if wordcount == 0:\n",
    "        continue\n",
    "    \n",
    "    for word in line.split():\n",
    "        for p in possible:\n",
    "            if word == p:\n",
    "                counter += 1\n",
    "                \n",
    "    \n",
    "    if counter / float(wordcount) > perc and linelen < max_len and linelen > min_len:\n",
    "        min_len -= 1\n",
    "        max_len -= 2\n",
    "        perc += 0.002\n",
    "        short_chosen.append(line)\n",
    "        out_file.write(auth + ': ' + line)\n",
    "        print(str(perc) + ': ' + line.rstrip())\n",
    "        \n",
    "    if len(short_chosen) > 70:\n",
    "        break\n",
    "    #max_line_counter += 1\n",
    "\n",
    "print(len(short_chosen))\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc: 0.429 length: 70 worlen_min: 60 - Louise:  shes been nothing but nice to me but well keep that our dirty ------\n",
      "perc: 0.308 length: 76 worlen_min: 60 - Fenderman1964:  its --------- -- ------- ------ here than it was --------- --------- to be\n",
      "perc: 0.357 length: 80 worlen_min: 60 - @erotic_kitty:  good thing she doesnt have the -------- her ------ would be going crazy ------\n",
      "perc: 0.333 length: 70 worlen_min: 60 - carrol:  pulls her legs up and curls up on the couch ------ her face to sleep\n",
      "perc: 0.333 length: 68 worlen_min: 60 - carrol:  --- you have to ---------- your --------- its a ---- here --------\n",
      "perc: 0.455 length: 117 worlen_min: 60 - Louise:  her back --------- ----- a tight ---- as her head falls back with ------ pulling back ------- his cock with her ass\n",
      "perc: 0.333 length: 88 worlen_min: 60 - ^fran:  turns around with her ass to the room what about this one -------- her ass up and down\n",
      "perc: 0.333 length: 94 worlen_min: 60 - Louise:  but mood ---- im very good just --------- got --------- on ------ and been so busy ------ --\n",
      "perc: 0.333 length: 83 worlen_min: 60 - @erotic_kitty:  then ----- with brie how to get ---------- to ---- out so he can ---- on his face\n",
      "perc: 0.45 length: 101 worlen_min: 60 - Valkyrie:  and i told her to tell me what she ---- when she looks at ------------ ------- me with her --------\n",
      "perc: 0.333 length: 82 worlen_min: 60 - carrol:  ----- softly as she feels him --------- her ass pushing her ass against his hand\n",
      "perc: 0.318 length: 117 worlen_min: 60 - +DJ`Mercury:  well as for working with people i ----- that will happen but im pretty sure you take care of -------- every morning\n",
      "perc: 0.407 length: 141 worlen_min: 60 - Cruel`Intentions:  -------- how she is sitting on him to -------- his lap and ----- her arms around his --------- as she ------- on his tongue between her own\n",
      "perc: 0.333 length: 83 worlen_min: 60 - +DJ`Mercury:  lets just say djwof that the guy who it -------- to was having a good laugh at me\n",
      "perc: 0.5 length: 71 worlen_min: 60 - +DJ`Mercury:  im not one for -------- just ------ and then only if its ------ right\n",
      "perc: 0.385 length: 72 worlen_min: 60 - @erotic_kitty{S}:  grins as she smiles at --------- hello sir what part where you licking\n",
      "perc: 0.353 length: 103 worlen_min: 60 - PlayfulBBC:  -------------- her ---- but not ---------- to ---- her mouth with his ------------ you you dirty slut\n",
      "perc: 0.345 length: 154 worlen_min: 60 - PlayfulBBC:  ------ his cock into --------- as fingers ---- into the ----- of her hips he feels her soft ass -------- against his ------ as he ------- out inside her\n",
      "perc: 0.368 length: 98 worlen_min: 60 - guynextdoor:  nods head no not at all legs feel like ------ with rain ------ on them --------- to ---- -------\n",
      "perc: 0.35 length: 111 worlen_min: 60 - +DJ`Mercury:  would like to be where she can go -------- year around but still ----- places that have snow for ------------\n",
      "perc: 0.375 length: 81 worlen_min: 60 - Louise:  i get that ------------ mine just is not and does not like or want anything sex\n",
      "perc: 0.455 length: 62 worlen_min: 60 - carrol:  we are lucky we do not get ---------- ----------- high -----\n",
      "perc: 0.538 length: 63 worlen_min: 60 - Jothom:  these guys have a good ----- but its just not that guys -----\n",
      "perc: 0.4 length: 65 worlen_min: 60 - @erotic_kitty:  ----- her ------- harder ----------- deeper into her with moans\n",
      "perc: 0.357 length: 70 worlen_min: 60 - @erotic_kitty:  i think most are -------- to ---------- but no not really im --- ---\n",
      "perc: 0.368 length: 75 worlen_min: 60 - Cruel`Intentions:  ya and i dont do this with my hair often so we will see if i do this more\n",
      "perc: 0.389 length: 89 worlen_min: 60 - Fenderman1964:  when i was -------- i ------ time on things like that but its not ----- my time anymore\n",
      "perc: 0.364 length: 70 worlen_min: 60 - @erotic_kitty:  im doing well thanks for asking nudisthusband --- how about yourself\n",
      "perc: 0.462 length: 61 worlen_min: 60 - +DJ`Mercury:  it hurt for like two ------- and im still not back at -----\n",
      "perc: 0.385 length: 72 worlen_min: 60 - Valkyrie:  ill finger her ---- ------------ she should feel good but not to -----\n",
      "perc: 0.375 length: 79 worlen_min: 60 - Jothom:  just started but so far -------- my ass from going on a --------- all is good\n",
      "perc: 0.385 length: 63 worlen_min: 60 - PlayfulBBC:  winks down at amie in his arms ------- her softly on her lips\n",
      "perc: 0.357 length: 74 worlen_min: 60 - Silver_haired`Fox:  they may come here for that but some stay for the -------- ----- -------\n",
      "perc: 0.412 length: 89 worlen_min: 60 - +DJ`Mercury:  hold on guys ------------ might not be your ---- but -- ------- that its quite the show\n",
      "perc: 0.357 length: 61 worlen_min: 60 - +DJ`Mercury:  if the ------ isnt ------ with beer it has no use for me --\n",
      "perc: 0.455 length: 103 worlen_min: 60 - Louise:  ----- sucking his ball so that she can lick his --- as her hand keeps ------- up and down on his cock\n",
      "perc: 0.5 length: 61 worlen_min: 60 - Louise:  your --------- would be just as ------ with the ---- --- on\n",
      "perc: 0.389 length: 84 worlen_min: 60 - carrol:  thats just as bad susancd and its one of my top - ------- why im not into --------\n",
      "perc: 0.368 length: 95 worlen_min: 60 - Jothom:  thats good to hear - but why are you here and not giving her your ---- ---------- attention p\n",
      "perc: 0.556 length: 63 worlen_min: 60 - @erotic_kitty:  -------------------- good ------- as we should all be -------\n",
      "perc: 0.5 length: 69 worlen_min: 60 - +DJ`Mercury:  ------- his cock back into her face and holds her on his cock again\n",
      "perc: 0.429 length: 69 worlen_min: 60 - carrol:  those are nice lips ----- but its not enough to bring kymmi back --\n",
      "perc: 0.364 length: 62 worlen_min: 60 - Valkyrie:  -------- your ------ ------ should be at its best in -------\n",
      "perc: 0.417 length: 62 worlen_min: 60 - Louise:  then she ------- her nick to that ------ but well ------ lol\n",
      "perc: 0.409 length: 117 worlen_min: 60 - Valkyrie:  looking down at her watching her ------- up at me as she ------- my cock balls -------- her ---- ------ lips ------\n",
      "perc: 0.385 length: 61 worlen_min: 60 - WhoGiveSaDamn:  its all ----- ----- -- she got me ----- up --------- -- lol\n",
      "perc: 0.4 length: 70 worlen_min: 60 - Sanger:  i still ------ because shes not very well here for me to ---- is she\n",
      "perc: 0.462 length: 67 worlen_min: 60 - @erotic_kitty:  pulls back letting his cock rest on her face licking at his balls\n",
      "perc: 0.381 length: 103 worlen_min: 60 - Anastatia:  dont ------ dont ----- too long dont hit on people dont pull --- --- at a play party things like that\n",
      "perc: 0.417 length: 63 worlen_min: 60 - Silver_haired`Fox:  yet there was always someone in your ---- that ----- that one\n",
      "perc: 0.467 length: 66 worlen_min: 60 - @erotic_kitty:  - in here we talk to all not just --- or straight female or male\n",
      "perc: 0.438 length: 85 worlen_min: 60 - @erotic_kitty:  ------- how -------------- looks at her in the way that makes her ---- at her knees\n",
      "perc: 0.412 length: 89 worlen_min: 60 - +DJ`Mercury:  hold on guys ------------ might not be your ---- but -- ------- that its quite the show\n",
      "perc: 0.417 length: 67 worlen_min: 60 - carrol:  moans as ---------- ---- for her again watching his cum ----- her\n",
      "perc: 0.417 length: 62 worlen_min: 60 - guynextdoor:  --------- line do you like --------- if not can i have yours\n",
      "perc: 0.417 length: 75 worlen_min: 60 - Valkyrie:  though its not just my ass everything about me just -------- ------------\n",
      "perc: 0.429 length: 68 worlen_min: 60 - @erotic_kitty:  amie what are you up to --- ------- -- -------- time with your one\n",
      "perc: 0.421 length: 98 worlen_min: 60 - carrol:  no thanks im good -- just ------- water its too late in the day for -------------- for me anyway\n",
      "perc: 0.417 length: 68 worlen_min: 60 - @erotic_kitty:  there could be ------------ or something like that and it wasnt me\n",
      "perc: 0.389 length: 98 worlen_min: 60 - @saffron{WH}:  eyes -------------- thinking she has ---- to ----- the ----- if need be so she just ------- back\n",
      "perc: 0.417 length: 63 worlen_min: 60 - carrol:  im okay not happy were getting snow here but ------- gonna do\n",
      "perc: 0.462 length: 67 worlen_min: 60 - Cruel`Intentions:  what is your name what is your ------ what is your -------- -----\n",
      "perc: 0.4 length: 67 worlen_min: 60 - Valkyrie:  well its more than enough - id be happy with it is what im saying\n",
      "perc: 0.467 length: 66 worlen_min: 60 - +DJ`Mercury:  no it was not it was just a question what you wanna to do smiles\n",
      "perc: 0.429 length: 61 worlen_min: 60 - Louise:  wait wait i have not ------- on any wait for me to ----- up\n",
      "perc: 0.4 length: 85 worlen_min: 60 - +DJ`Mercury:  waves at jenn giving her an ------------ --------- as she ---- ------- on her chair\n",
      "perc: 0.462 length: 61 worlen_min: 60 - Anastatia:  was looking for ----- but knew he would not be on --- later\n",
      "perc: 0.419 length: 162 worlen_min: 60 - guynextdoor:  throws his head back as that cock ------- his balls ---------- up as he ----- his ----- hot ---- into her mouth -------- her pink tongue with that hot white cum\n",
      "perc: 0.429 length: 70 worlen_min: 60 - @erotic_kitty:  laughs at mrd as she ------ her tongue out and ------ in her -------\n",
      "perc: 0.455 length: 113 worlen_min: 60 - sweet_teresa:  just grins at him as she ----- her coffee -------- hi ----- but letting him have that one for making the coffee\n",
      "perc: 0.462 length: 66 worlen_min: 60 - @erotic_kitty:  if you are ---------- you are ------- with where and how you are\n",
      "perc: 0.438 length: 73 worlen_min: 60 - @erotic_kitty:  if im in the mood ----- but not tonight hehe ---- its too cold for that\n",
      "perc: 0.417 length: 64 worlen_min: 60 - Threeleggedcat:  its not ------- if youre not making something on the side jenn\n",
      "perc: 0.5 length: 65 worlen_min: 60 - Louise:  ---- that ----- would have to be here just as much to know that\n",
      "perc: 0.417 length: 67 worlen_min: 60 - @erotic_kitty:  i ------- that -------- sex was -------- but with just more -----\n",
      "perc: 0.421 length: 108 worlen_min: 60 - +DJ`Mercury:  slides his tongue against her open ----- ------- her as she pulls him into her -------- here ------- -----\n",
      "perc: 0.471 length: 69 worlen_min: 60 - Fenderman1964:  i dont have a ----- if i had one its not me thats gonna be in there\n",
      "perc: 0.444 length: 89 worlen_min: 60 - Louise:  i wouldnt ---- that at all a nice ------- with me ------ up ------- down your throat --\n",
      "perc: 0.429 length: 61 worlen_min: 60 - Louise:  grins as she looks at the man who just sit down at her side\n",
      "perc: 0.5 length: 63 worlen_min: 60 - Louise:  -------------------- i dont have that on my -----------------\n",
      "perc: 0.429 length: 69 worlen_min: 60 - Woman:  madmick if its too thin she wont feel it no ------ how she --------\n",
      "perc: 0.455 length: 70 worlen_min: 60 - Anastatia:  ----- his tongue out --------- at ----------- -------- softly at her\n",
      "perc: 0.476 length: 100 worlen_min: 60 - WhoGiveSaDamn:  but i was innocent so its all good just --- there for -- days is all rolling on the floor laughing\n",
      "perc: 0.471 length: 72 worlen_min: 60 - Woman:  i have no idea if that was the ----- i was looking for but ill take it\n",
      "perc: 0.5 length: 76 worlen_min: 60 - carrol:  ------------ back into ------------- ----- in your ------- well n all that\n",
      "perc: 0.429 length: 75 worlen_min: 60 - Anastatia:  no ----- on ----- --------- so long as your cunt is --------- for -------\n",
      "perc: 0.462 length: 72 worlen_min: 60 - Silver_haired`Fox:  i dont really do the -------- ------- -------------- so its all good d\n",
      "perc: 0.438 length: 81 worlen_min: 60 - @saffron{WH}:  stop now his green eyes ------- her ----- face ---------- as she looks up at me\n",
      "perc: 0.45 length: 105 worlen_min: 60 - guynextdoor:  no ---- on --------- but what if they give your -------- a ------- that could just ---- your whole week\n",
      "perc: 0.467 length: 70 worlen_min: 60 - +DJ`Mercury:  oh nice how long are you on -------- for and how are you -------- it\n",
      "perc: 0.471 length: 78 worlen_min: 60 - +DJ`Mercury:  im sure she is a ------ but im good you two ----- on with your ------ ------\n",
      "perc: 0.444 length: 62 worlen_min: 60 - +DJ`Mercury:  which stretches do you do for your ----------- nordicgoddess\n",
      "perc: 0.471 length: 92 worlen_min: 60 - @erotic_kitty{S}:  laughs at ----------- no need to roll your eyes we are all just making -------- ----- here\n",
      "perc: 0.462 length: 65 worlen_min: 60 - WhoGiveSaDamn:  last year there --------------- was not as good as it use to be\n",
      "perc: 0.45 length: 86 worlen_min: 60 - carrol:  no i dont think so its a funny thing im one of those people that like to be ------ p\n",
      "perc: 0.444 length: 75 worlen_min: 60 - @erotic_kitty{S}:  lol i just got back home so i couldnt be here but im glad i was missed --\n",
      "perc: 0.458 length: 110 worlen_min: 60 - @erotic_kitty:  will do thank you working on some ----- my ---------- ---- me so im not all here or there as the case may be\n",
      "perc: 0.533 length: 79 worlen_min: 60 - Louise:  description for annora im not interested its not you its me im an ----- bitch\n",
      "perc: 0.471 length: 78 worlen_min: 60 - Valkyrie:  no not enough to keep me on too much longer but might check on back later on\n",
      "perc: 0.455 length: 61 worlen_min: 60 - carrol:  smiles and hugs her kissing her back --------- hello my one\n",
      "perc: 0.5 length: 68 worlen_min: 60 - WhoGiveSaDamn:  what is that face for - looks like your ----- are -------- out ---\n",
      "perc: 0.643 length: 64 worlen_min: 60 - @erotic_kitty{S}:  maybe its two but its one of those that look like its just one\n",
      "perc: 0.5 length: 71 worlen_min: 60 - Louise:  i have heard her ------------------- almost as good as you are ------\n",
      "perc: 0.455 length: 62 worlen_min: 60 - @saffron{WH}:  ty ---------------------- - i like yours as well how are you\n",
      "perc: 0.529 length: 84 worlen_min: 60 - +DJ`Mercury:  ------- his cock -------- with her face as she ---- at his ----- looking up at him\n",
      "perc: 0.462 length: 65 worlen_min: 60 - +DJ`Mercury:  id go out for more but its about ----- one ------- or something\n",
      "perc: 0.545 length: 64 worlen_min: 60 - @erotic_kitty:  in -------- --------- we have ---------- as well as ----- here\n",
      "perc: 0.471 length: 72 worlen_min: 60 - Woman:  i have no idea if that was the ----- i was looking for but ill take it\n",
      "perc: 0.529 length: 82 worlen_min: 60 - Silver_haired`Fox:  we were talking about how she cant see what she is or what she really looks like\n",
      "perc: 0.476 length: 97 worlen_min: 60 - @erotic_kitty{S}:  well i have a -------- for a reason if he was interested in that he would have ----- me but hey\n",
      "perc: 0.467 length: 75 worlen_min: 60 - @erotic_kitty{S}:  its not like im -------- an ------ creative name myself so what do i know\n",
      "perc: 0.526 length: 96 worlen_min: 60 - Cruel`Intentions:  ------- her head on his -------- ------- his cock again but not if its going to come with that\n",
      "perc: 0.5 length: 61 worlen_min: 60 - Fenderman1964:  all the ------ ----- are here is that what youre ------- me\n",
      "perc: 0.5 length: 65 worlen_min: 60 - Louise:  ---- that ----- would have to be here just as much to know that\n",
      "perc: 0.5 length: 80 worlen_min: 60 - Woman:  ------ herself back looking up in his eyes as she takes his cock into her lips\n",
      "perc: 0.5 length: 65 worlen_min: 60 - @erotic_kitty:  not me ----------- came up with that - shes the ----------- one\n",
      "perc: 0.545 length: 63 worlen_min: 60 - Sanger:  she was so ------------ when she -------- it was just -------\n",
      "perc: 0.5 length: 80 worlen_min: 60 - Jothom:  so ------------- how small are we talking ------------------------- or -------\n",
      "perc: 0.5 length: 80 worlen_min: 60 - Jothom:  so ------------- how small are we talking ------------------------- or -------\n",
      "perc: 0.529 length: 82 worlen_min: 60 - Silver_haired`Fox:  we were talking about how she cant see what she is or what she really looks like\n",
      "perc: 0.5 length: 71 worlen_min: 60 - +DJ`Mercury:  im not one for -------- just ------ and then only if its ------ right\n",
      "perc: 0.538 length: 65 worlen_min: 60 - WhoGiveSaDamn:  ------ not ------- for that much here and your just ----- of me\n",
      "perc: 0.5 length: 63 worlen_min: 60 - Louise:  how do people think with a name like battlecat that im female\n",
      "perc: 0.5 length: 76 worlen_min: 60 - carrol:  she just doesnt like those that -------- with her thats not -- problem lol\n",
      "perc: 0.5 length: 65 worlen_min: 60 - Valkyrie:  we dont have face ------- ------- that will suck out your -----\n",
      "perc: 0.533 length: 79 worlen_min: 60 - Louise:  description for annora im not interested its not you its me im an ----- bitch\n",
      "perc: 0.538 length: 65 worlen_min: 60 - WhoGiveSaDamn:  ------ not ------- for that much here and your just ----- of me\n",
      "perc: 0.526 length: 96 worlen_min: 60 - Cruel`Intentions:  ------- her head on his -------- ------- his cock again but not if its going to come with that\n",
      "perc: 0.5 length: 83 worlen_min: 60 - Fenderman1964:  --------------------------- ------------------------- wolfinthealley here as well\n",
      "perc: 0.529 length: 84 worlen_min: 60 - +DJ`Mercury:  ------- his cock -------- with her face as she ---- at his ----- looking up at him\n",
      "###########################################################################################################################\n",
      "second part\n",
      "###########################################################################################################################\n",
      "perc: 0.5 length: 63 worlen_min: 60 wordlen_max: 70 - Louise:  how do people think with a name like battlecat that im female\n",
      "perc: 0.5 length: 60 worlen_min: 59 wordlen_max: 69 - +DJ`Mercury:  well if you cant with that body what would i be ---- to do\n",
      "perc: 0.538 length: 63 worlen_min: 58 wordlen_max: 68 - Jothom:  these guys have a good ----- but its just not that guys -----\n",
      "perc: 0.5 length: 58 worlen_min: 57 wordlen_max: 67 - Louise:  -------- have one that has -------- am so you can not be\n",
      "perc: 0.538 length: 65 worlen_min: 56 wordlen_max: 66 - WhoGiveSaDamn:  ------ not ------- for that much here and your just ----- of me\n",
      "perc: 0.545 length: 56 worlen_min: 55 wordlen_max: 65 - Anastatia:  takes her hands up into his and ----- fingers with her\n",
      "perc: 0.571 length: 59 worlen_min: 54 wordlen_max: 64 - @erotic_kitty:  and no i do not have ------------------------------------\n",
      "perc: 0.556 length: 58 worlen_min: 53 wordlen_max: 63 - carrol:  what do you have ------- for your morning --------------\n",
      "perc: 0.545 length: 60 worlen_min: 52 wordlen_max: 62 - @erotic_kitty{S}:  its all good ------------- just dont call me late to -----\n",
      "perc: 0.545 length: 57 worlen_min: 51 wordlen_max: 61 - guynextdoor:  who said i was good dont be --------- ------- like that\n",
      "perc: 0.636 length: 51 worlen_min: 50 wordlen_max: 60 - PlayfulBBC:  no i dont ---------- i dont like that word at all\n",
      "perc: 0.615 length: 54 worlen_min: 49 wordlen_max: 59 - Threeleggedcat:  if we are good ----- one day will be be on our heads\n",
      "perc: 0.545 length: 52 worlen_min: 48 wordlen_max: 58 - carrol:  so i do wonder what ------ are fucking up with now\n",
      "perc: 0.545 length: 56 worlen_min: 47 wordlen_max: 57 - Anastatia:  takes her hands up into his and ----- fingers with her\n",
      "perc: 0.538 length: 53 worlen_min: 46 wordlen_max: 56 - @erotic_kitty:  so it aint all that bad if you look at it like that\n",
      "perc: 0.636 length: 46 worlen_min: 45 wordlen_max: 55 - Anastatia:  no ------- at all just not ur place to do so\n",
      "perc: 0.556 length: 53 worlen_min: 44 wordlen_max: 54 - @erotic_kitty:  what does she enjoy ------- what are her ----------\n",
      "perc: 0.556 length: 45 worlen_min: 43 wordlen_max: 53 - @erotic_kitty:  smiles as she wiggles her butt in hello all\n",
      "perc: 0.625 length: 43 worlen_min: 42 wordlen_max: 52 - PlayfulBBC:  well thats good its just ------ cold here\n",
      "perc: 0.556 length: 43 worlen_min: 41 wordlen_max: 51 - +DJ`Mercury:  thats good --- ----- its just not for now\n",
      "perc: 0.556 length: 44 worlen_min: 40 wordlen_max: 50 - @erotic_kitty:  ---- are fun but they dont have that -----\n",
      "perc: 0.667 length: 44 worlen_min: 39 wordlen_max: 49 - +DJ`Mercury:  was it as good for you as it was for me --\n",
      "perc: 0.556 length: 44 worlen_min: 38 wordlen_max: 48 - Silver_haired`Fox:  so she might have been here longer than me\n",
      "perc: 0.625 length: 38 worlen_min: 37 wordlen_max: 47 - @erotic_kitty{S}:  not if you keep up with your -------\n",
      "perc: 0.556 length: 42 worlen_min: 36 wordlen_max: 46 - @erotic_kitty{S}:  mmm you can do all that with me --------\n",
      "perc: 0.7 length: 38 worlen_min: 35 wordlen_max: 45 - PlayfulBBC:  im not sure if i was ---- or she was\n",
      "perc: 0.625 length: 39 worlen_min: 34 wordlen_max: 44 - guynextdoor:  well that was almost a ------ for her\n",
      "perc: 0.571 length: 36 worlen_min: 33 wordlen_max: 43 - Threeleggedcat:  moves his cock back into her mouth\n",
      "perc: 0.571 length: 35 worlen_min: 32 wordlen_max: 42 - @erotic_kitty:  ----- me how to do that sarahgood\n",
      "perc: 0.571 length: 33 worlen_min: 31 wordlen_max: 41 - +DJ`Mercury:  aww we are all friends here ---\n",
      "perc: 0.625 length: 33 worlen_min: 30 wordlen_max: 40 - @erotic_kitty:  oh no no your --- was just fine\n",
      "perc: 0.556 length: 38 worlen_min: 29 wordlen_max: 39 - Cruel`Intentions:  - well its at night but ill be there\n",
      "perc: 0.556 length: 37 worlen_min: 28 wordlen_max: 38 - @erotic_kitty:  cool im good too so what you up too\n",
      "perc: 0.571 length: 35 worlen_min: 27 wordlen_max: 37 - @erotic_kitty:  ----- me how to do that sarahgood\n",
      "perc: 0.571 length: 29 worlen_min: 26 wordlen_max: 36 - Fenderman1964:  well i do have all three --\n",
      "perc: 0.571 length: 30 worlen_min: 25 wordlen_max: 35 - Threeleggedcat:  - im good thanks how are you\n",
      "perc: 0.6 length: 25 worlen_min: 24 wordlen_max: 34 - +DJ`Mercury:  not much just ------ up\n",
      "perc: 0.6 length: 27 worlen_min: 23 wordlen_max: 33 - @erotic_kitty:  so its -------- all night\n",
      "perc: 0.6 length: 25 worlen_min: 22 wordlen_max: 32 - @saffron{WH}:  what are you into kymmi\n",
      "perc: 0.714 length: 29 worlen_min: 21 wordlen_max: 31 - @saffron{WH}:  no idea what that is but me\n",
      "perc: 0.6 length: 23 worlen_min: 20 wordlen_max: 30 - guynextdoor:  guess not so well lol\n",
      "perc: 0.6 length: 25 worlen_min: 19 wordlen_max: 29 - carrol:  im ------ for good ----\n",
      "perc: 0.6 length: 24 worlen_min: 18 wordlen_max: 28 - Silver_haired`Fox:  its still early for me\n",
      "perc: 0.6 length: 26 worlen_min: 17 wordlen_max: 27 - Valkyrie:  im not -------- up blood\n",
      "perc: 0.6 length: 23 worlen_min: 16 wordlen_max: 26 - @erotic_kitty{S}:  well im not --- -----\n",
      "perc: 0.667 length: 19 worlen_min: 15 wordlen_max: 25 - Louise:  its not ---------\n",
      "perc: 0.667 length: 21 worlen_min: 14 wordlen_max: 24 - @erotic_kitty:  nice on -----------\n",
      "perc: 0.75 length: 19 worlen_min: 13 wordlen_max: 23 - Fenderman1964:  well that was fun\n",
      "perc: 0.667 length: 15 worlen_min: 12 wordlen_max: 22 - @erotic_kitty:  well its true\n",
      "perc: 0.667 length: 15 worlen_min: 11 wordlen_max: 21 - Threeleggedcat:  that was then\n",
      "perc: 1.0 length: 11 worlen_min: 10 wordlen_max: 20 - @erotic_kitty:  not on me\n",
      "perc: 0.667 length: 12 worlen_min: 9 wordlen_max: 19 - carrol:  that u are\n",
      "perc: 0.667 length: 16 worlen_min: 8 wordlen_max: 18 - carrol:  im good thanks\n",
      "perc: 0.667 length: 15 worlen_min: 7 wordlen_max: 17 - WhoGiveSaDamn:  she does that\n",
      "perc: 0.667 length: 15 worlen_min: 6 wordlen_max: 16 - Louise:  im right here\n",
      "perc: 1.0 length: 7 worlen_min: 5 wordlen_max: 15 - @erotic_kitty{S}:  hello\n",
      "perc: 0.667 length: 13 worlen_min: 4 wordlen_max: 14 - +DJ`Mercury:  have i what\n",
      "perc: 0.667 length: 12 worlen_min: 3 wordlen_max: 13 - Jothom:  ---- me up\n",
      "perc: 0.667 length: 11 worlen_min: 2 wordlen_max: 12 - WhoGiveSaDamn:  no no ---\n",
      "perc: 1.0 length: 9 worlen_min: 1 wordlen_max: 11 - Valkyrie:  be well\n",
      "perc: 1.0 length: 5 worlen_min: 0 wordlen_max: 10 - @erotic_kitty:  out\n",
      "perc: 1.0 length: 5 worlen_min: 0 wordlen_max: 9 - +DJ`Mercury:  his\n",
      "perc: 1.0 length: 6 worlen_min: 0 wordlen_max: 8 - carrol:  your\n",
      "perc: 1.0 length: 6 worlen_min: 0 wordlen_max: 7 - carrol:  with\n",
      "perc: 1.0 length: 5 worlen_min: 0 wordlen_max: 6 - carrol:  for\n",
      "perc: 1.0 length: 4 worlen_min: 0 wordlen_max: 5 - ^fran:  im\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# structure TWO\n",
    "# uses top 0.025 dashed out sentences \n",
    "# part 1: 130 lines: gradient from percentage of most common words from 0.3 to 0.6 and minimum sentence length of 60\n",
    "# part 2: 70 lines: percentage increased linearly and reducing word length baries towards very short sentences\n",
    "# uses original authors from big dashed out sentence database\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "possible = ['for', 'her', 'that', 'hello', 'on', 'me', 'hey', 'are', 'with', 'good', 'all', 'im', 'have', 'as', 'up', 'at', 'your', \n",
    "            'not', 'like', 'his', 'be', 'just', 'no', 'so', 'its', 'how', 'back', 'out', 'one', 'but', 'was', 'what', 'if', 'dont', \n",
    "            'well', 'here', 'or', 'she', 'we', 'do', 'nice', 'into']\n",
    "\n",
    "def checkline(line):\n",
    "    line = line.split(':')\n",
    "    if len(line) < 2:\n",
    "        return False\n",
    "    line = line[1]\n",
    "    if len(line) < 2:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "#input_file = open('1406_only_top0.025_all.txt', mode='r', encoding='utf8').readlines()\n",
    "input_file = open('1606_only_top0.025_all_authordistfix.txt', mode='r', encoding='utf8').readlines()\n",
    "\n",
    "dofirst = True\n",
    "add_prameters = True\n",
    "finlines = []\n",
    "perc = 0.3\n",
    "perc_increase = 0.0015\n",
    "wordlen_min = 60\n",
    "linecount_first = 130\n",
    "linecount_second = 70\n",
    "\n",
    "if dofirst:\n",
    "    for i in range(linecount_first):\n",
    "        while True:\n",
    "            line = random.choice(input_file)\n",
    "            if not checkline(line):\n",
    "                line = random.choice(input_file)\n",
    "                continue   \n",
    "            auth = line.split(':')[0]\n",
    "            line = line.split(':')[1]\n",
    "\n",
    "            counter = 0\n",
    "            wordcount = len(line.split())\n",
    "\n",
    "            if wordcount == 0:\n",
    "                continue\n",
    "\n",
    "            linelen = len(line)\n",
    "            for word in line.split():\n",
    "                for p in possible:\n",
    "                    if word == p:\n",
    "                        counter += 1\n",
    "            currentperc = counter / float(wordcount)\n",
    "            if currentperc > perc and linelen > wordlen_min and line not in finlines: \n",
    "                if add_prameters:\n",
    "                    print(str(round(currentperc, 3)) + ';' + str(linelen) + ';' + str(wordlen_min) + ';' + auth + ': ' + line.rstrip())\n",
    "                    finlines.append('perc: ' + str(round(currentperc, 3)) + ' - ' + auth + ': ' + line)\n",
    "                else:\n",
    "                    print(auth + ': ' + line.rstrip())\n",
    "                    finlines.append(auth + ': ' + line)\n",
    "                perc += perc_increase\n",
    "                break\n",
    "\n",
    "print('###########################################################################################################################')\n",
    "print('second part')\n",
    "print('###########################################################################################################################')\n",
    "\n",
    "wordlen_min = 60\n",
    "wordlen_max = 70\n",
    "wordlen_decrease = 1\n",
    "for i in range(linecount_second):\n",
    "    tried = 0\n",
    "    while True and tried < 10000:\n",
    "        tried += 1\n",
    "        line = random.choice(input_file)\n",
    "        if not checkline(line):\n",
    "            line = random.choice(input_file)\n",
    "            continue   \n",
    "        auth = line.split(':')[0]\n",
    "        line = line.split(':')[1]\n",
    "            \n",
    "        counter = 0\n",
    "        wordcount = len(line.split())\n",
    "        \n",
    "        if wordcount == 0:\n",
    "            continue\n",
    "        \n",
    "        linelen = len(line)\n",
    "        for word in line.split():\n",
    "            for p in possible:\n",
    "                if word == p:\n",
    "                    counter += 1\n",
    "        currentperc = counter / float(wordcount)\n",
    "        if currentperc > perc and linelen > wordlen_min and linelen < wordlen_max and line not in finlines: \n",
    "            if add_prameters:\n",
    "                print('perc: ' + str(round(currentperc, 3)) + ' length: '+str(linelen) + ' worlen_min: ' + str(wordlen_min) + ' wordlen_max: ' + str(wordlen_max) + ' - ' + auth + ': ' + line.rstrip())\n",
    "                finlines.append('perc: ' + str(round(currentperc, 3)) + ' - ' + auth + ': ' + line)\n",
    "            else:\n",
    "                print(auth + ': ' + line.rstrip())\n",
    "                finlines.append(auth + ': ' + line)\n",
    "            perc += perc_increase\n",
    "            wordlen_min -= wordlen_decrease\n",
    "            wordlen_min = max(wordlen_min, 0)\n",
    "            wordlen_max -= wordlen_decrease\n",
    "            wordlen_max = max(wordlen_max, 4)\n",
    "            break\n",
    "            \n",
    "print(len(finlines))\n",
    "\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H%M%S')\n",
    "\n",
    "outfile = open('1606_structure_02_01_'+st+'.txt', 'w')\n",
    "outfile.write('ACT 3 - STRUCTURE 2\\n')\n",
    "for line in finlines:\n",
    "    outfile.write(line)\n",
    "outfile.close()\n",
    "\n",
    "# legend\n",
    "# perc = percent of top20 words in the sentence\n",
    "# length = character length of the sentence\n",
    "# wordlen_min = minimum char length \n",
    "# wordlen_max = maximum char length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "111\n",
      "125\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "# count i/s in 410/501\n",
    "leaves410 = 0\n",
    "entrances410 = 0\n",
    "leaves501 = 0\n",
    "entrances501 = 0\n",
    "\n",
    "for line in codecs.open('1006/410_utf8.txt', mode='r', encoding='utf-8'):\n",
    "    if 'has left' in line or 'has quit' in line:\n",
    "        leaves410 += 1\n",
    "    if 'joined the channel' in line:\n",
    "        entrances410 += 1\n",
    "    #if ':' in line and not in_blocklist(blocklist, line.strip()): # blocked?:\n",
    "        #sentence = line[line.find(\":\"):]\n",
    "        #all_posts.append((author, sentence.strip().lower()))\n",
    "        #all_posts_410.append((author, sentence.strip().lower()))\n",
    "\n",
    "        #author = line[:line.find(\":\")]\n",
    "        #if author not in authors: # save things\n",
    "            #authors[author] = set() # init list for author\n",
    "        #if author not in authors_410:\n",
    "            #authors_410[author] = set()\n",
    "        #authors[author].add(sentence.strip().lower())\n",
    "        #authors_410[author].add(sentence.strip().lower())\n",
    "\n",
    "\n",
    "for s in codecs.open(\"1006/501_utf8.txt\", mode='r', encoding='utf-8').readlines():\n",
    "    if 'has left' in s or 'has quit' in s:\n",
    "        leaves501 += 1\n",
    "    if 'joined the channel' in s:\n",
    "        entrances501 += 1\n",
    "    #if ':' in s and 'has left the channel' not in s and 'has quit' not in s and 'joined the channel' not in s:\n",
    "        #if not in_blocklist(blocklist, s.strip()): # blocked?\n",
    "            #sentence = s[s.find(\">\")+2:]\n",
    "            #all_posts.append((author, sentence.strip().lower()))\n",
    "            #all_posts_501.append((author, sentence.strip().lower()))\n",
    "\n",
    "            #author = s[s.find(\"<\")+1:s.find(\">\")]\n",
    "            #if author not in authors: # save things\n",
    "            #    authors[author] = set() # init list for author\n",
    "            #if author not in authors_501:\n",
    "            #    authors_501[author] = set()\n",
    "            #authors[author].add(sentence.strip().lower())\n",
    "            #authors_501[author].add(sentence.strip().lower()) \n",
    "            \n",
    "            \n",
    "         \n",
    "print(leaves410)\n",
    "print(entrances410)\n",
    "print(leaves501)\n",
    "print(entrances501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import random\n",
    "\n",
    "def get_random_syn(word):\n",
    "    r = word\n",
    "    syns = wn.synsets(word)\n",
    "    lemmas = []\n",
    "    for ss in syns:\n",
    "        for lem in ss.lemma_names():\n",
    "            lemmas.append(lem)\n",
    "            #r = lem\n",
    "            #if lem is not word:\n",
    "            #    return lem\n",
    "    return lemmas\n",
    "\n",
    "def replace_sentence(sentence):\n",
    "    return_sentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        lemmas = get_random_syn(word)\n",
    "        if len(lemmas) > 0:\n",
    "            #print(word + str(lemmas))\n",
    "            r = random.choice(lemmas)\n",
    "            if r is \"atomic_number_53\":\n",
    "                r = 'I'\n",
    "            return_sentence += r + \" \"\n",
    "        else:\n",
    "            return_sentence += word + ' '\n",
    "    return return_sentence\n",
    "\n",
    "\n",
    "\n",
    "for i in range(500):\n",
    "    \n",
    "    sen = random.choice(all_posts)\n",
    "    if len(sen[1]) > 10:\n",
    "        print('-------------------------')\n",
    "        print(sen[1])\n",
    "        print(replace_sentence(sen[1]))\n",
    "        print(replace_sentence(sen[1]))\n",
    "        print(replace_sentence(sen[1]))\n",
    "        print(replace_sentence(sen[1]))\n",
    "        print(replace_sentence(sen[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURVES generation\n",
    "\n",
    "random.seed(1)\n",
    "#render_plain('1306_removed_digits_entrances_01_ORIGINAL.txt', 500, 3860)\n",
    "#render_by_osc('osc_config_500_late_slowexp.csv', '1306_cleaner_group1&2&3_01.txt', 3860)\n",
    "print('finito')\n",
    "#generate_lines_linear(20)\n",
    "\n",
    "generate_lines_from(0.00, 0.0001, 10)\n",
    "print(\"####################################################################################\")\n",
    "generate_lines_from(0.10, 0.0001, 10)\n",
    "print(\"####################################################################################\")\n",
    "generate_lines_from(0.20, 0.0001, 10)\n",
    "print(\"####################################################################################\")\n",
    "generate_lines_from(0.50, 0.0001, 10)\n",
    "print(\"####################################################################################\")\n",
    "generate_lines_from(0.80, 0.0001, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving word groups\n",
    "lists = []\n",
    "#lists.append((1, 5))\n",
    "#lists.append((6, 20))\n",
    "#lists.append((21, 50))\n",
    "#lists.append((51, 100))\n",
    "#lists.append((101, 500))\n",
    "lists.append((3000, 10000))\n",
    "\n",
    "outfile = codecs.open('3000_10000_groups.txt', 'w')\n",
    "\n",
    "for l in lists:\n",
    "    possible_words = []\n",
    "    #_config = config[index]\n",
    "    _min = l[0]\n",
    "    _max = l[1]\n",
    "    app_list = []\n",
    "    for i in range(_min, _max+1):\n",
    "        app_list.append(i)\n",
    "\n",
    "    # all allowed words\n",
    "    selected_appearances = get_by_appearance_list(app_list)\n",
    "    outfile.write(' '.join(selected_appearances))\n",
    "    #possible_words.append((selected_appearances, _config))\n",
    "    \n",
    "outfile.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocess act1&2\n",
    "\n",
    "for sentence in all_posts_501:\n",
    "    print(sentence[0] + \" -> \" + remove_non_frequent(get_topn_percent(0.01), sentence[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
